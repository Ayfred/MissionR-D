{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#TÃ©lÃ©chargement des packages Python/spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.42036581039429\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "import spacy\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le fichier CSV dans un dataframe\n",
    "df = pd.read_csv('GooglePlayReviews.csv')\n",
    "\n",
    "# Fonction pour dÃ©tecter la langue d'un commentaire\n",
    "def detect_language(comment):\n",
    "    try:\n",
    "        lang = detect(comment)\n",
    "        return lang\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Filtrer les commentaires en franÃ§ais\n",
    "df_fr = df[df['commentaire'].apply(lambda x: detect_language(x)=='fr')]\n",
    "\n",
    "df_fr.to_csv('Comments_FiltrÃ©s.csv', index=False, header = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lecture du fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open the CSV file using the csv module\n",
    "with open('Comments_FiltrÃ©s.csv', newline='',  encoding='utf-8') as csvfile:\n",
    "    # create a csv reader object\n",
    "    reader = csv.reader(csvfile)\n",
    "    # create an empty list to store the strings\n",
    "    string_list = []\n",
    "    # loop through each row in the CSV file\n",
    "    for row in reader:\n",
    "        # add the string to the list\n",
    "        #if detect(row[0]) == 'fr':\n",
    "        string_list.append(row[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemple de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exemple de texte\n",
    "text = \"Selon WikipÃ©dia il l'appelle Laura ðŸ˜ŠðŸ˜ŠðŸ˜Š(hezignborzingiozrnoivznioznvionzo), La ponctuation est gÃ©nial lâ€™ensemble des signes qui, dans lâ€™Ã©crit, marquent les divisions et les liaisons des phrases et des membres 'de phrase'. Vous pouvez en apprendre plus sur \\\"la ponctuation\\\" en visitant ce site: https://www.larousse.fr/dictionnaires/francais/ponctuation/63717 parce que ce lien donne beaucoup d'informations intÃ©ressantes. ðŸ˜Š\"\n",
    "#text = \"FonctionnalitÃ©s, salut car beau temps aujourd'hui\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etapes du texte Preprocessing\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "listStopWords = [str(x) for x in nlp.Defaults.stop_words]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Processing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove explanations : Bonjour, Avis aux Amateurs et Professionnels, Depuis une dizaine de jours, et quelques sorties Course Ã  pied, je n'ai plus accÃ¨s aux donnÃ©es \"Moyenne \" dans la synthÃ¨se proposÃ© par l'application : plus d'allure moyenne, plus de rythme moyen, et plus de vitesse moyenne, etc. Avez une explication et/ou solution. Sinon trÃ¨s bonne application, ou il manque un mode fractionnÃ©. TrÃ¨s ergonomique et trÃ¨s intuitive. Merci ðŸ˜\n",
      "remove leopaul ' : Bonjour, Avis aux Amateurs et Professionnels, Depuis une dizaine de jours, et quelques sorties Course Ã  pied, je n ai plus accÃ¨s aux donnÃ©es \"Moyenne \" dans la synthÃ¨se proposÃ© par l application : plus d allure moyenne, plus de rythme moyen, et plus de vitesse moyenne, etc. Avez une explication et/ou solution. Sinon trÃ¨s bonne application, ou il manque un mode fractionnÃ©. TrÃ¨s ergonomique et trÃ¨s intuitive. Merci ðŸ˜\n",
      "remove quotes : Bonjour, Avis aux Amateurs et Professionnels, Depuis une dizaine de jours, et quelques sorties Course pied, je ai plus accÃ¨s aux donnÃ©es \"Moyenne dans la synthÃ¨se proposÃ© par application plus allure moyenne, plus de rythme moyen, et plus de vitesse moyenne, etc. Avez une explication et/ou solution. Sinon trÃ¨s bonne application, ou il manque un mode fractionnÃ©. TrÃ¨s ergonomique et trÃ¨s intuitive. Merci \n",
      "remove links: Bonjour, Avis aux Amateurs et Professionnels, Depuis une dizaine de jours, et quelques sorties Course pied, je ai plus accÃ¨s aux donnÃ©es \"Moyenne dans la synthÃ¨se proposÃ© par application plus allure moyenne, plus de rythme moyen, et plus de vitesse moyenne, etc. Avez une explication et/ou solution. Sinon trÃ¨s bonne application, ou il manque un mode fractionnÃ©. TrÃ¨s ergonomique et trÃ¨s intuitive. Merci \n",
      "remove phone numbers and contacts: Bonjour  Avis Amateurs Professionnels  Depuis dizaine jours  quelques sorties Course pied  ai accÃ¨s donnÃ©es  Moyenne la synthÃ¨se proposÃ© application allure moyenne  rythme moyen  plus de vitesse moyenne   Avez explication solution  Sinon bonne application  ou il manque mode fractionnÃ©  TrÃ¨s ergonomique trÃ¨s intuitive  Merci \n",
      "remove pronoum and determinant : Bonjour   Avis Amateurs Professionnels   Depuis dizaine jours   sorties Course pied   ai accÃ¨s donnÃ©es   Moyenne synthÃ¨se proposÃ© application allure moyenne   rythme moyen   plus de vitesse moyenne    Avez explication solution   Sinon bonne application   ou manque mode fractionnÃ©   TrÃ¨s ergonomique trÃ¨s intuitive   Merci \n",
      "remove proper noun :       dizaine jours    sorties pied    ai accÃ¨s donnÃ©es    synthÃ¨se proposÃ© application allure moyenne    rythme moyen    plus de vitesse moyenne     explication solution    bonne application    ou manque mode fractionnÃ©    ergonomique trÃ¨s intuitive   \n",
      "      dizaine jours    sorties pied    ai accÃ¨s donnÃ©es    synthÃ¨se proposÃ© application allure moyenne    rythme moyen    plus de vitesse moyenne     explication solution    bonne application    ou manque mode fractionnÃ©    ergonomique trÃ¨s intuitive   \n"
     ]
    }
   ],
   "source": [
    "def united(text):\n",
    "    doc =  text.split(\" \");\n",
    "    # ItÃ©rer Ã  travers chaque token dans le document\n",
    "    for token in doc:\n",
    "\n",
    "        #Remove explanations\n",
    "        # Si le token est \"parce que\", \"car\" ou \"puisque\", supprimer tous les tokens suivants dans la phrase\n",
    "        if token in [\"parce\", \"car\", \"puisque\"]:\n",
    "            doc = doc[:token.index()]\n",
    "            break\n",
    "    \n",
    "    # Supprimer tout ce qui est entre parenthÃ¨ses\n",
    "    sentence = ' '.join(doc)\n",
    "    sentence = re.sub(r'\\([^()]*\\)', '', sentence)\n",
    "\n",
    "    print(f\"remove explanations : {sentence}\")\n",
    "\n",
    "    \n",
    "    #Removal of ' and the char that precede it\n",
    "    sentence = sentence.replace(\"'\", \" \")\n",
    "\n",
    "    print(f\"remove leopaul ' : {sentence}\")\n",
    "\n",
    "    words = sentence.split(\" \")\n",
    "    newSentence = \"\"\n",
    "    for word in words:\n",
    "        if len(word) > 1:\n",
    "            newSentence += word + \" \"\n",
    "    sentence = newSentence\n",
    "    \n",
    "    print(f\"remove quotes : {sentence}\")\n",
    "\n",
    "    sentence = re.sub('http[s]?://\\S+', '', sentence)\n",
    "\n",
    "    print(f\"remove links: {sentence}\")\n",
    "\n",
    "\n",
    "    # Regular expressions for phone numbers and email addresses\n",
    "    phone_regex = r\"(?<!\\d)(?:\\d[ -/\\\\_\\d]*){10}(?!\\d)\"\n",
    "    email_regex = r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\"  # matches john.doe@example.com\n",
    "\n",
    "    # Find phone numbers and email addresses in the sentence\n",
    "    sentence = re.sub(phone_regex,\"\", sentence)\n",
    "    sentence = re.sub(email_regex,\"\", sentence)\n",
    "    sentence = re.sub(r'[^\\w]', ' ', sentence)\n",
    "    doc = sentence.split(\" \")\n",
    "    for word in doc:\n",
    "        if word in listStopWords:\n",
    "            doc.remove(word)\n",
    "    \n",
    "    sentence = ' '.join(doc)\n",
    "\n",
    "    print(f\"remove phone numbers and contacts: {sentence}\")\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    #texte = doc.text\n",
    "    text = \"\"\n",
    "    for token in doc:\n",
    "        if (token.pos_ == \"PRON\" or token.pos_ == \"DET\"):\n",
    "            continue\n",
    "        else:\n",
    "            if not token.text.__contains__(\"'\"):\n",
    "                text += token.text\n",
    "                text += \" \"\n",
    "    sentence = text\n",
    "\n",
    "    print(f\"remove pronoum and determinant : {sentence}\")\n",
    "\n",
    "\n",
    "    doc = nlp(sentence)\n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if not (token.ent_type_ == \"ORG\" or token.ent_type_ == \"PERSON\" or token.text.istitle()):\n",
    "            result.append(token.text)\n",
    "    sentence =  \" \".join(result)\n",
    "    print(f\"remove proper noun : {sentence}\")\n",
    "\n",
    "    return sentence\n",
    "\n",
    "\"\"\"\n",
    "for string in string_list:\n",
    "    united_string = united(string)\n",
    "    string_list_clean.append(united_string)\n",
    "print(string_list_clean)\n",
    "#run\n",
    "#print(united(text))\"\"\"\n",
    "united_string = united(string_list[0])\n",
    "print(united_string)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dizaine jours sorties pied ai accÃ¨s donnÃ©es synthÃ¨se proposÃ© application allure moyenne rythme moyen plus de vitesse moyenne explication solution bonne application ou manque mode fractionnÃ© ergonomique trÃ¨s intuitive \n"
     ]
    }
   ],
   "source": [
    "testttt = \"\"\n",
    "for token in nlp(united_string):\n",
    "    if (token.pos_ != \"SPACE\"):\n",
    "        testttt += token.text\n",
    "        testttt += \" \"\n",
    "print(testttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, Avis aux Amateurs et Professionnels, Depuis une dizaine de jours, et quelques sorties Course Ã  pied, je n'ai plus accÃ¨s aux donnÃ©es \"Moyenne \" dans la synthÃ¨se proposÃ© par l'application : plus d'allure moyenne, plus de rythme moyen, et plus de vitesse moyenne, etc. Avez une explication et/ou solution. Sinon trÃ¨s bonne application, ou il manque un mode fractionnÃ©. TrÃ¨s ergonomique et trÃ¨s intuitive. Merci ðŸ˜\n"
     ]
    }
   ],
   "source": [
    "print(string_list[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Part 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                dizaine   jours      sorties     pied      n     accÃ¨s   donnÃ©es   synthÃ¨se   proposÃ©     application      d     allure   moyenne      plus   rythme   moyen      plus   de   vitesse   moyenne         explication      solution        bonne   application      manque   mode   fractionnÃ©        ergonomique   trÃ¨s   intuitive          '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "united_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chat\n",
      "assoie\n",
      "sur\n",
      "canapÃ©\n",
      "rouge\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define list of POS patterns to detect\n",
    "patterns = [\n",
    "    (\"noun noun\", [\"NOUN\", \"NOUN\"]),\n",
    "    (\"verb noun\", [\"VERB\", \"NOUN\"]),\n",
    "    (\"adjective noun\", [\"ADJ\", \"NOUN\"]),\n",
    "    (\"noun conjunction\", [\"NOUN\", \"CONJ\"]),\n",
    "    (\"noun adjective\", [\"NOUN\", \"ADJ\"]),\n",
    "    (\"noun noun noun\", [\"NOUN\", \"NOUN\", \"NOUN\"]),\n",
    "    (\"verb pronoun noun\", [\"VERB\", \"PRON\", \"NOUN\"]),\n",
    "    (\"verb noun noun\", [\"VERB\", \"NOUN\", \"NOUN\"]),\n",
    "    (\"verb adjective noun\", [\"VERB\", \"ADJ\", \"NOUN\"]),\n",
    "    (\"adjective adjective noun\", [\"ADJ\", \"ADJ\", \"NOUN\"]),\n",
    "    (\"noun preposition noun\", [\"NOUN\", \"ADP\", \"NOUN\"]),\n",
    "    (\"verb determiner noun\", [\"VERB\", \"DET\", \"NOUN\"]),\n",
    "    (\"verb noun preposition noun\", [\"VERB\", \"NOUN\", \"ADP\", \"NOUN\"]),\n",
    "    (\"adjective noun noun noun\", [\"ADJ\", \"NOUN\", \"NOUN\", \"NOUN\"]),\n",
    "    (\"adjective conjunction adjective\", [\"ADJ\", \"CONJ\", \"ADJ\"]),\n",
    "    (\"verb preposition adjective noun\", [\"VERB\", \"ADP\", \"ADJ\", \"NOUN\"]),\n",
    "    (\"verb pronoun adjective noun\", [\"VERB\", \"PRON\", \"ADJ\", \"NOUN\"]),\n",
    "    (\"noun conjunction noun noun\", [\"NOUN\", \"CONJ\", \"NOUN\", \"NOUN\"]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the reference patterns and check if there is a match in the sentence\n",
    "for pattern, pos_tags_pattern in patterns:\n",
    "    if len(pos_tags_pattern) != len(doc):\n",
    "        continue  # Skip patterns with different number of words\n",
    "    match = True\n",
    "    for i in range(len(doc)):\n",
    "        if pos_tags_pattern[i] != doc[i].pos_:\n",
    "            match = False\n",
    "            break\n",
    "    if match:\n",
    "        print(f\"Detected pattern '{pattern}' in sentence '{united_string}'\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input sentence\n",
    "sentence = \"The cat sat on the mat\"\n",
    "\n",
    "# Process the sentence with spaCy\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Iterate through the reference patterns and check if there is a match in the sentence\n",
    "for pattern, pos_tags_pattern in patterns:\n",
    "    if len(pos_tags_pattern) != len(doc):\n",
    "        continue  # Skip patterns with different number of words\n",
    "    match = True\n",
    "    for i in range(len(doc)):\n",
    "        if pos_tags_pattern[i] != doc[i].pos_:\n",
    "            match = False\n",
    "            break\n",
    "    if match:\n",
    "        print(f\"Detected pattern '{pattern}' in sentence '{sentence}'\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceByPattern = [[] for i in range((18))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"chat vert assoie sur canapÃ© rouge\"\n",
    "doc = nlp(testttt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      \n",
      "dizaine\n",
      "jours\n",
      "   \n",
      "sorties\n",
      "pied\n",
      "   \n",
      "ai\n",
      "accÃ¨s\n",
      "donnÃ©es\n",
      "   \n",
      "synthÃ¨se\n",
      "proposÃ©\n",
      "application\n",
      "allure\n",
      "moyenne\n",
      "   \n",
      "rythme\n",
      "moyen\n",
      "   \n",
      "plus\n",
      "de\n",
      "vitesse\n",
      "moyenne\n",
      "    \n",
      "explication\n",
      "solution\n",
      "   \n",
      "bonne\n",
      "application\n",
      "   \n",
      "ou\n",
      "manque\n",
      "mode\n",
      "fractionnÃ©\n",
      "   \n",
      "ergonomique\n",
      "trÃ¨s\n",
      "intuitive\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(doc) - 3):\n",
    "    if doc[i].pos_ == \"NOUN\":\n",
    "        if doc[i + 1].pos_ == \"CONJ\" and doc[i + 2].pos_ == \"NOUN\":\n",
    "            if doc[i + 3].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[17].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text + \" \" + doc[i + 3].text)\n",
    "                break\n",
    "            else:\n",
    "                sentenceByPattern[4].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "                break\n",
    "        elif doc[i + 1].pos_ == \"PREP\" and doc[i + 2].pos_ == \"NOUN\":\n",
    "            sentenceByPattern[11].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "            break\n",
    "        elif doc[i + 1].pos_ == \"NOUN\":\n",
    "            if doc[i + 2].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[6].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "                break\n",
    "            else:\n",
    "                sentenceByPattern[1].append(doc[i].text + \" \" + doc[i + 1].text)\n",
    "                break\n",
    "    elif doc[i].pos_ == \"VERB\":\n",
    "        if doc[i + 1].pos_ == \"PRON\":\n",
    "            if doc[i + 2].pos_ == \"ADJ\" and doc[i + 3].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[17].append(doc[i].text + \" \"+ doc[i + 1].text + \" \" + doc[i + 2].text + \" \" + doc[i + 3].text)\n",
    "                break\n",
    "            if doc[i + 2].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[7].append(doc[i].text +\" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "                break\n",
    "        elif doc[i + 1].pos_ == \"PREP\" and doc[i + 2].pos_ == \"ADJ\" and doc[i + 3].pos_ == \"NOUN\":\n",
    "            sentenceByPattern[16].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text + \" \" + doc[i + 3].text)\n",
    "        elif doc[i + 1].pos_ == \"NOUN\" :\n",
    "            if doc[i + 2].pos_ == \"PREP\" and doc[i + 3].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[13].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text + \" \" + doc[i + 3].text)\n",
    "                break\n",
    "            elif doc[i + 2].pos_ == \"NOUN\":\n",
    "                sentenceByPattern[8].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "                break\n",
    "            else:\n",
    "                sentenceByPattern[2].append(doc[i].text + \" \" + doc[i + 1].text)\n",
    "                break\n",
    "        elif doc[i + 1].pos_ == \"DET\" and doc[i + 2].pos_ == \"NOUN\":\n",
    "            sentenceByPattern[12].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "            break\n",
    "        elif doc[i + 1].pos_ == \"ADJ\" and doc[i + 2].pos_ == \"NOUN\":\n",
    "            sentenceByPattern[9].append(doc[i].text + \" \" + doc[i + 1].text + \" \" +doc[i + 2].text)\n",
    "            break\n",
    "    elif doc[i].pos_ == \"ADJ\" :\n",
    "        if doc[i + 1].pos_ == \"CONJ\" and doc[i + 2].pos_ == \"ADJ\":\n",
    "            sentenceByPattern[15].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "            break\n",
    "        elif doc[i + 1].pos_ == \"NOUN\":\n",
    "            if doc[i + 2].pos_ == \"NOUN\":\n",
    "                if doc[i + 3].pos_ == \"NOUN\":\n",
    "                    sentenceByPattern[14].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text + \" \" + doc[i + 3].text)\n",
    "                    break\n",
    "                else:\n",
    "                    sentenceByPattern[5].append(doc[i].text + \" \" + doc[i + 1].text + \" \" + doc[i + 2].text)\n",
    "                    break\n",
    "            else:\n",
    "                sentenceByPattern[3].append(doc[i].text + \" \" + doc[i + 1].text)\n",
    "                break\n",
    "        elif doc[i + 1].pos_ == \"ADJ\" and doc[i + 2].pos_ == \"NOUN\":\n",
    "            sentenceByPattern[10].append(doc[i].text + \" \" + doc[i + 1].text +\" \" + doc[i + 2].text)\n",
    "            break\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['dizaine jours'],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " [],\n",
       " []]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentenceByPattern"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
